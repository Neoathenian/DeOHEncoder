{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Read recipe inputs\n",
    "Joined_scores2 = dataiku.Dataset(\"Joined_scores2\")\n",
    "Joined_scores2_df = Joined_scores2.get_dataframe()\n",
    "\n",
    "\n",
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function decodes onehotencoded columns that start with colname (and eliminates those columns)\n",
    "def DeOneHotEncodeColumn(df,colname):\n",
    "    #These are the columns we think are onehotencoded\n",
    "    cols_tryout=[col for col in df.columns if colname+\"_\"==col[:len(colname)+1]]\n",
    "    #The cols from cols_tryout aren´t necessarily binary, so we´ll check\n",
    "    cols=[]\n",
    "    for col in cols_tryout:\n",
    "        EsBin=True\n",
    "        i=0\n",
    "        #This other version I think could be faster when there are only ones and 0s faster (python faster on vector ops)\n",
    "        #unicos=df[col].unique()\n",
    "        #if len(unicos)<=2:\n",
    "        #    for a in unicos:\n",
    "        #        if a not in [0,1]:\n",
    "        #            EsBin=False\n",
    "\n",
    "        while EsBin and i<df.shape[0]:\n",
    "            if df[col][i]!=0 and df[col][i]!=1:\n",
    "                EsBin=False\n",
    "            i+=1\n",
    "        if EsBin:\n",
    "            cols.append(col)\n",
    "    #If there aren´t at least 2 binary columns... what are u doing lol\n",
    "    if len(cols)<2:\n",
    "        return df\n",
    "    sol=np.array([\"\" for i in range(df.shape[0])],dtype=\"object\")\n",
    "    #Let´s get the output of our decoded column ()\n",
    "    for col in cols:\n",
    "        sol+=np.array([col[len(colname)+1:] if x else \"\" for x in df[col]],dtype=\"object\")\n",
    "\n",
    "    #Let´s drop the columns we used and put the decoded column in place :)\n",
    "    df[colname]=sol\n",
    "    df=df.drop(cols,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds all the positions where char is in word\n",
    "def findall(char,word):\n",
    "    pos=[word.find(char)]\n",
    "    suma=pos[0]+1\n",
    "    while pos[-1]!=-1:\n",
    "        pos.append(word[suma:].find(char))\n",
    "        suma+=pos[-1]+1#(hay que sumar 1 por el \"_\" que hay que borrar)\n",
    "    if pos[0]==-1:\n",
    "        return pos\n",
    "    pos=pos[:-1]\n",
    "    suma=pos[0]\n",
    "    for i in range(1,len(pos)):\n",
    "        suma+=pos[i]+1#Hay que sumar 1 por los arrays empiezan en 0)\n",
    "        pos[i]=suma\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function detects all the possible columns that have been one hot encoded, it does so by checking for _\n",
    "#This is because when creating a OH of \"EVENT\" we get columns such as EVENT_SPAIN, EVENT_FRANCE....\n",
    "#Since the column we´re looking for is EVENT_TYPE, we´re gonna make sure to be able to get the longest string that ends in _\n",
    "#And that is at the beginning of multiple column names\n",
    "def Detect_OHcols(df):\n",
    "    cols=df.columns\n",
    "    future_colnames=[]\n",
    "    for i in range(len(cols)):\n",
    "        pos=findall(\"_\",cols[i])\n",
    "        names=[cols[i][:p] for p in pos]\n",
    "        name_final=\"\"\n",
    "        for name in names:\n",
    "            possible_columns=[]\n",
    "            long=len(name)\n",
    "            for j in range(i+1,len(cols)):\n",
    "                if name==cols[j][:long]:\n",
    "                    possible_columns.append(cols[j])\n",
    "            if len(possible_columns)>=1:\n",
    "                name_final=name\n",
    "            if name_final not in future_colnames and name_final!=\"\":\n",
    "                future_colnames.append(name_final)\n",
    "\n",
    "    return future_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We´re gonna detect the columns, sort their names so that EVENT_TYPE is done before EVENT...and done :)\n",
    "def DeOneHotEncode(df,exclude=[]):\n",
    "    cols=pd.Series(Detect_OHcols(df))\n",
    "    cols=cols.sort_values(ascending=False)\n",
    "    for col in cols:\n",
    "        if col not in exclude:\n",
    "            df=DeOneHotEncodeColumn(df,col)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "Joined_scores_DeOH_df = DeOneHotEncode(Joined_scores2_df,exclude=[\"pred\"]) # For this sample code, simply copy input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "Joined_scores_DeOH = dataiku.Dataset(\"Joined_scores_DeOH\")\n",
    "Joined_scores_DeOH.write_with_schema(Joined_scores_DeOH_df)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_Joined_scores_DeOH",
  "createdOn": 1661413828042,
  "creationTag": {
   "lastModifiedBy": {
    "login": "mariana.nastase@groupama.ro"
   },
   "lastModifiedOn": 1661413828042,
   "versionNumber": 0
  },
  "creator": "mariana.nastase@groupama.ro",
  "customFields": {},
  "dkuGit": {
   "lastInteraction": 0
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
